---
title: "Lez_2x2: Tavole (o tabelle) di contingenza. La pratica"
output: 
        ioslides_presentation:
                # rmdtable.css works just on the pandoc-made tables (the ones with |---|)
                widescreen: true
                df_print: paged
                logo: files/logo.png
                css: [files/gio_milligram.css, files/rmdtable.css] # milligram is modified by me
        github_document:
                toc: TRUE
                toc_depth: 2 # default = 3
always_allow_html: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      echo = TRUE,
                      include = TRUE,
                      message = TRUE,
                      warning = TRUE,
                      fig.width = 7,
                      fig.height = 4)
```

```{r, include=FALSE}
library(tidyverse)

library(ggplot2)
theme_set(theme_bw()) # set the theme for all the plot

library(knitr)

options("kableExtra.html.bsTable" = T) # forces the package to use the boostrap css
library(kableExtra)
```

```{r, include=FALSE}
# shortcut for nice tables formatting

kab <- function(table,
                position = "center", 
                full_width = TRUE, 
                colnames_rotation = 0, 
                SB = TRUE,
                width = "100%",
                height = "100%",
                ...) {
    kable(table, ...) %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                     position = position,
                full_width = full_width,
                font_size = 18) %>%
        row_spec(row = 0, angle = colnames_rotation) %>%
        scroll_box(width = width, height = height)
}
```

## I dati di partenza

Carichiamo i dati da un foglio Excel:

```{r, message=FALSE}
library(readxl)
read_excel(path = "files/data.xlsx")
```

---

Le specie sono state mescolate per mantenere la riservatezza del dataset.  
L'unica variabile corretta è `Pseudotsuga menziesii`, che è la specie di riferimento delle misurazioni.

I numeri son abbondanze relative (percentuali di copertura) di diverse specie.  
La tabella ha (come dovrebbe) le specie sulle colonne, le misure di copertura sulle righe.

---

Controlliamo la tabella:

```{r}
DB <- read_excel(path = "files/data.xlsx")[, -1] # eliminiamo la colonna con i nomi
str(DB)
```

---

La colonna del castagno è stata identificata come `chr` perché alcune caselle hanno dei `.` invece che `0`. Si correggono subito e si trasforma di nuovo la variabile in `num`:

```{r}
DB$`Castanea sativa`[DB$`Castanea sativa` == "."] <- 0 # spazi nei nomi delle 
# colonne ci costringono a usare gli apici ` [alt + \]

# Non la metto subito al suo posto nel DB perché facilmente con as.numeric si 
# perdono dei dati che potrei voler ricostruire
Castanea_sativa <- as.numeric(DB$`Castanea sativa`) 
```

Il programma avvisa che uno dei valori non era numerico, e quindi è stato perso.

---

Confrontiamo i `NA` della colonna del `DB` con quelli della variabile `Castanea_sativa`

```{r}
DB$`Castanea sativa`[is.na(Castanea_sativa) & !is.na(DB$`Castanea sativa`)]
```

Questa `O` al posto dello `0` è un problema classico, si corregge facilmente:

```{r}
Castanea_sativa[DB$`Castanea sativa` == "O"] <- 0
DB$`Castanea sativa` <- Castanea_sativa
```

```{r}
sum(is.na(DB)) # in queste tabelle se ci sono zeri non ci dovrebbero essere NA
```

---

Ce sono 3 `NA` che non si spiegano, in questo caso:

1. Si ricontrollano i cartacei da cui sono stati trascritti i dati
2. Si chiedono delucidazioni al rilevatore
3. Si sceglie se imputare i dati mancanti o recuperarli in qualche altro modo

Nel nostro caso erano degli errori di battitura di celle che avrebbero dovuto essere `0`.

```{r}
DB$`Castanea sativa`[is.na(DB$`Castanea sativa`)] <- 0
```


```{r}
min(DB) # mi aspetto che il minimo sia 0, e conti come assenza
max(DB) # che sia sopra il 100% non è un problema, se è spiegato nei M&M
```

---

È importante che le variabili siano di tipo **binomiale**, in questo caso dati di presenza/assenza.

La prassi è sostituire tutte le coperture `>0` con un `1`.

```{r}
DB[DB > 0] <- 1
```


## La tabella di contingenza

Consideriamo le variabili `Pseudotsuga menziesii` e `Clematis vitalba`:

```{r}
PSEMEN <- DB$`Pseudotsuga menziesii`
CLEVIT <- DB$`Clematis vitalba`
```

la tabella di contingenza si crea con un solo comando:

```{r}
tavola_PSEMEN_CLEVIT <- table(PSEMEN, CLEVIT)
tavola_PSEMEN_CLEVIT
```

## Presupposti delle misure

**Il campionamento è di tipo multinomiale**: il numero dei plot da misurare è stato deciso prima di iniziare le misure.

**La tabella non è condizionata**: una volta arrivati sui plot si sono scelti punti con un principio completamente indipendente dalla presenza o meno di _Douglasia_ o di _vitalba_, i totali marginali non erano assolutamente prevedibili.

## Le nostre 3 domande

Ritorniamo alle nostre 3 specifiche domande:

1. I due criteri di classificazione (le due variabili) sono indipendenti?
2. Uno dei due valori di una variabile è più comune in uno dei valori della seconda variabile? (c'è una differenza con il punto 2)
3. La proporzione di una variabile è uguale a quella dell'altra?

Nel nostro caso cerchiamo di tradurre le domande:

1. La presenza della _Douglasia_ è indipendente da quella della _vitalba_
2. La _Douglasia_ si rinnova meno dove c'è la _vitalba_?
3. La proporzione di plot con la _Douglasia_ è uguale alla proporzione di plot con la _vitalba_?

_vale la pena di notare che la domanda numero 3 in questo caso può essere interessante, come no_

## P-hacking | cose che tutti fanno ma nessuno lo dice!

È importante riconoscere che le domande dovrebbero essere state decise **prima di andare in campo**, solo in questo caso i p-value hanno un vero significato.

* siamo ancora nel campo dell'_hypothesis testing_

Sel la domanda viene scelta dopo aver visto i dati (ma a un buon forestale spesso basta vedere il bosco) i p-value diventano solo indicativi, e siamo tenuti a scriverlo a chiare lettere:

* siamo nel campo delle _analisi esplorative_

## 1. Test di indipendenza delle variabili

Nessuna delle caselle è `0`, quindi si procede con il **'N-1' Pearson's Chi-Squared Test**
Si ricorda che nel caso **2x2** il test è equivalente al **Mantel-Haenszel Chi-Squared senza la correzione per la continuità** 

Prima si crea un vettore necessario per il test composto da un numero N di cifre uguali:

```{r}
stratum <- rep(1, length(PSEMEN)) # la lunghezza di una qualsiasi variabile è = N
```

La funzione `mantelhaen.test()` nel nostro caso ha bisogno di 4 argomenti:

1. La prima variabile
2. La seconda variabile
3. Un vettore che identifichi gli strati (nel nostro caso tutto uguale)
4. `correct = FALSE`, per evitare di applicare la _correzione per la continuità_

---

```{r}
mantelhaen.test(PSEMEN, CLEVIT, stratum, correct = FALSE)
```

Nel nostro caso il p-value è ben maggiore di 0.05. Le variabili risultano indipendenti.

## 2. Test per la differenza di proporzioni

In questo caso ci chiediamo se ci sia più _vitalba_ dove la _Douglasia_ non si rinnova:

* L'ipotesi $H_0$ è che le proporzioni di _vitalba_ derivino da un'unico tipo di plot, che non risente della rinnovazione o meno della douglasia, in questo caso $p$ è la proporzione di plot con rinnovazione di _vitalba_: $$H_0 : p_{NOdouglasia} - p_{douglasia} = 0$$
* Calcoliamo la differenza di proporzioni dei dati è 
$$\hat{p}_{NOdouglasia} - \hat{p}_{douglasia} = \frac{6}{9} - \frac{7}{19}$$

---

```{r}
diff_p <- (tavola_PSEMEN_CLEVIT[1, 2]/sum(tavola_PSEMEN_CLEVIT[1, ])) - (tavola_PSEMEN_CLEVIT[2, 2]/sum(tavola_PSEMEN_CLEVIT[2, ]))
diff_p
```

La funzione vuole le variabili inserite come colonne di un `data.frame`, e nel caso di variabili qualitative (come le nostre) che siano colonne di tipo `factor` invece che `numeric`

```{r}
data <- data.frame(CLEVIT = as.factor(CLEVIT), PSEMEN = as.factor(PSEMEN))
```

---

```{r, message=FALSE}
library(statsr)
set.seed(42) # la funzione inference usa dei metodi casuali, per assicurare la 
# riproducibilità dei risultati è necessario impostare il `seed`
inference(CLEVIT, PSEMEN, data = data, type = "ht", statistic = "proportion", 
          success = "1", method = "simulation", order = c("0", "1"), null = 0, 
          alternative = "greater", nsim = 10000, 
          show_eda_plot = FALSE, show_inf_plot = FALSE)
```

---

```{r, message=FALSE}
set.seed(42)
inference(CLEVIT, PSEMEN, data = data, type = "ht", statistic = "proportion", 
          success = "1", method = "simulation", order = c("0", "1"), null = 0, 
          alternative = "greater", nsim = 10000, 
          show_var_types = FALSE, show_summ_stats = FALSE, show_res = FALSE)
```

## 3. Test di McNemar

```{r, echo=FALSE}
mcnemar_midp <- function(contingency_table_2x2, tail = "two", verbose = TRUE) {
    # from [kylebgorman mcnemar.midp function](https://gist.github.com/kylebgorman/4e3ac8b6b67bccbcff8e)
    
    # Compute McNemar's test using the "mid-p" variant suggested by:
    #  
    # M.W. Fagerland, S. Lydersen, P. Laake. 2013. The McNemar test for 
    # binary matched-pairs data: Mid-p and asymptotic are better than 
    # exact conditional. BMC Medical Research Methodology 13: 91.
    
    d1 <- dim(contingency_table_2x2)
    d2 <- c(2,2)
    good <- all.equal(d1, d2)
    
    if (!good) stop("\nThis test is valid only for 2x2 tables\n")
    
    b <- contingency_table_2x2[1, 2]
    c <- contingency_table_2x2[2, 1]
    
    if (b+c < 6) {warning("When 'b' + 'c' cells are below 6, the literature suggest other tests\n")}
    
    n <- b + c
    x <- min(b, c)
    p <- 2 * pbinom(x, n, .5, lower.tail = TRUE)
    if (tail == "two") {midp <- p - dbinom(x, n, .5)}
    if (tail == "one") {midp <- (p - dbinom(x, n, .5))/2}
    
    if (verbose) {writeLines(paste0("mid-p McNemar test, ",
                                    tail,
                                    "-sided version\n    mid-p-value = ",
                                    round(midp, 3),
                                    "\n"))
    }
    
    result <- list(mid.p = midp, type = paste0(tail, "-sided"))
    
    return(invisible(result))
}
```

Poichè $c + d > 6$ possiamo utilizzare il **mid-$p$ Test di McNemar**, in questo caso abbiamo scritto una funzione apposita: `mcnemar_midp()`

```{r}
mcnemar_midp(tavola_PSEMEN_CLEVIT)$mid.p
```

Il $p$-value ottenuto supera 0.05, quindi non possiamo rifiutare l'$H_0$.

Le proporzioni di **Douglasia** non sono significativamente differenti da quelle della **vitalba**.

# Confrontare variabili multiple

---

Mettiamo ora il caso che (come in pratica spesso capita) io voglia confrontare una molteplicità di variabili fra loro:

mettiamo il caso più semplice (come è effettivamente il nostro), che io voglia confrontare tutte le specie erbacee rilevate con la rinnovazione di _douglasia_.

In questo caso ripartiamo dal `DB`:

```{r}
head(DB)
```

## Le tabelle di contingenza

Mettiamo da parte la colonna `Pseudotsuga menziesii` teniamo tutte le altre variabili in un `data.frame`. Come ricordiamo un `data.frame` è essenzialmente una `list` di colonne:

```{r}
PSEMEN <- DB$`Pseudotsuga menziesii`
herbs <- DB[, -1]
```

invece di una tavola di contingenza possiamo a questo punto creare una lista di tavole di contingenza:

```{r}
tavole_di_contingenza <- lapply(herbs, table, PSEMEN)
tavole_di_contingenza[1]
```

## P-hacking | cose che tutti fanno ma nessuno lo dice!

A questo punto abbiamo allegramente abbandonato il mondo dell'_Hypothesis testing_, stiamo letteralmente andando a caccia di risultati.

Questo non ci vieta di controllare la validità dei p-value che otteniamo: sarà importante alla fine applicare dei metodi di correzione per le comparazioni multiple.

## 1. Test di indipendenza delle variabili

possiamo controllare automaticamente quali delle tavole hanno delle caselle `= 0`:

ricordandomi che `lapply()` lavora sul contenuto dell'$i$-esimo elemento, non sull'elemento stesso.  
cfr. `list[i]` con `list[[i]]`

```{r}
tavole_di_contingenza[[1]] == 0 # controllo cosa succede al primo elemento
```

```{r}
sum(tavole_di_contingenza[[1]] == 0) # si costruisce la funzione un passo alla volta
```

---

Adesso sono pronto ad applicarlo alla `list` 

```{r}
tavole_con_zeri <- lapply(tavole_di_contingenza, function(x) sum(x == 0))
```

Ho ottenuto una lista con `0` per le tavole senza zeri, e numeri maggiori di `0` per tavole con degli zeri.

```{r}
herbs_con_zeri <- tavole_di_contingenza[tavole_con_zeri > 0]
herbs_senza_zeri <- tavole_di_contingenza[tavole_con_zeri == 0]
```

---

Nei casi in cui delle caselle è `0`, si procede con il **'N-1' Pearson's Chi-Squared Test**
Si ricorda che nel caso **2x2** il test è equivalente al **Mantel-Haenszel Chi-Squared senza la correzione per la continuità** 

Prima recuperiamo le colonne giuste: il punto chiave è che i loro nomi sono gli stessi degli elementi della lista `herbs_senza_zeri`

```{r}
DB_senza_zeri <- herbs[, names(herbs_senza_zeri)]
```


Prima si crea una lista di vettor necessari per il test, composti da un numero N di cifre uguali.
Nel nostro caso **tutti gli N sono uguali** quindi posso usare un vettore solo:

```{r}
stratum <- rep(1, length(PSEMEN)) # la lunghezza di una qualsiasi variabile è = N
```

---

La funzione `mantelhaen.test()` nel nostro caso ha bisogno di 4 argomenti:

1. La prima variabile
2. La seconda variabile
3. Un vettore che identifichi gli strati (nel nostro caso tutto uguale)
4. `correct = FALSE`, per evitare di applicare la _correzione per la continuità_

---

```{r}
test_senza_zeri <- lapply(DB_senza_zeri, 
                          function(x) mantelhaen.test(PSEMEN, x, stratum, correct = FALSE))
test_senza_zeri[[1]]$p.value
```

andiamo a recuperare i p-value dai test:

```{r}
p_value_senza_zeri <- lapply(test_senza_zeri, function(x) x$p.value)
sort(unlist(p_value_senza_zeri)) # trasforma la lista in un `named vector` che 
# si stampa molto più agevolmente
```

---

Prima recuperiamo le colonne giuste: il punto chiave è che i loro nomi sono gli stessi degli elementi della lista `herbs_con_zeri`

```{r}
DB_con_zeri <- herbs[, names(herbs_con_zeri)]
```


La funzione `fisher.test()` nel nostro caso ha bisogno di 2 argomenti:

1. La prima variabile (deve essere di tipo `factor`)
2. La seconda variabile (deve essere di tipo `factor`)

---

```{r}
PSEMEN <- as.factor(PSEMEN)
DB_con_zeri <- lapply(DB_con_zeri, as.factor)

test_con_zeri <- lapply(DB_con_zeri, function(x) fisher.test(PSEMEN, x))

test_con_zeri[[1]]
```

---

```{r}
test_con_zeri[[1]]$p.value
```

andiamo a recuperare i p-value dai test:

```{r}
p_value_con_zeri <- lapply(test_con_zeri, function(x) x$p.value)
sort(unlist(p_value_con_zeri))
```

---

A questo punto si applica la correzione per le comparazioni multiple:

```{r}
p_values <- c(p_value_con_zeri, p_value_senza_zeri)
adjusted_p_values <- p.adjust(p_values, method = "BH")
sort(adjusted_p_values)
```


## 2. Test per la differenza di proporzioni

Controlliamo quali tavole hanno tutte le celle >10:

```{r}
tavole_di_contingenza[[1]] < 10 # controllo cosa succede al primo elemento
sum(tavole_di_contingenza[[1]] < 10) # si costruisce la funzione un passo alla volta
```

---

Adesso sono pronto ad applicarlo alla `list` 

```{r}
caselle_poco_numerose <- lapply(tavole_di_contingenza, function(x) sum(x < 10))
tavole_di_contingenza[caselle_poco_numerose == 0]
```

Non ci sono tavole senza `caselle < 10`, dobbiamo ricorrere alla simulazione numerica per tutte le tavole.

---

In questo caso ci chiediamo se ci sia più o meno una specie, dove la _Douglasia_ si rinnova:

* L'ipotesi $H_0$ è che le proporzioni di ogni specie derivino da un'unico tipo di plot, che non risente della rinnovazione o meno della _douglasia_, in questo caso $p$ è la proporzione di plot con rinnovazione di una data specie: $$H_0 : p_{douglasia} - p_{NOdouglasia} = 0$$
* Calcoliamo la differenza di proporzioni dei dati è 
$$\hat{p}_{douglasia} - \hat{p}_{NOdouglasia}$$

---

```{r}
tavole_di_contingenza[[1]]
diff_p <- (tavole_di_contingenza[[1]][2, 2]/sum(tavole_di_contingenza[[1]][ , 2])) - (tavole_di_contingenza[[1]][2, 1]/sum(tavole_di_contingenza[[1]][ , 1]))
diff_p
```

```{r}
diff_p <- lapply(tavole_di_contingenza, 
                 function(x) (x[2, 2]/sum(x[ , 2])) - (x[2, 1]/sum(x[ , 1])))
diff_p[1]
```

---

```{r}
specie_adatte <- diff_p[diff_p > 0]
specie_inadatte <- diff_p[diff_p < 0]
```

La funzione vuole le variabili inserite come colonne di un `data.frame`, e nel caso di variabili qualitative (come le nostre) che siano colonne di tipo `factor` invece che `numeric`

```{r}
data <- data.frame(lapply(herbs, as.factor))
data <- cbind(PSEMEN, data)
```

```{r}
herbs_adatte <- cbind(PSEMEN, herbs[names(specie_adatte)])
herbs_inadatte <- cbind(PSEMEN, herbs[names(specie_inadatte)])
```


---

E adesso un trucco ignobile per utilizzare una lista di `string` deove andrebbe il nome della variabile in `non-standard evaluation`.

```{r}
names(data) <- lapply(names(data), function(x) sub("\\.", "_", x))
# gli spazi erano stati sostituiti da punti quando si è imposta la forma `data.frame`
names(herbs_adatte) <- lapply(names(herbs_adatte), function(x) sub(" ", "_", x))
names(herbs_inadatte) <- lapply(names(herbs_inadatte), function(x) sub(" ", "_", x))
# adesso tutti i nomi hanno la stessa forma
```


```{r, message=FALSE}
set.seed(42) # non dimenticare
test_adatte <- lapply(names(herbs_adatte), 
                      function(x) inference(eval(parse(text = x)), PSEMEN, 
                                            data = data, type = "ht", 
                                            statistic = "proportion",
                                            success = "1", method = "simulation", 
                                            order = c("1", "0"), null = 0, 
                                            alternative = "greater", nsim = 10000, 
                                            verbose = FALSE))
```

---

```{r, message=FALSE}
set.seed(42)
test_inadatte <- lapply(names(herbs_inadatte), 
                        function(x) inference(eval(parse(text = x)), PSEMEN, 
                                              data = data, type = "ht", 
                                              statistic = "proportion", 
                                              success = "1", method = "simulation", 
                                              order = c("1", "0"), null = 0, 
                                              alternative = "less", nsim = 10000,
                                              verbose = FALSE))
```

---

```{r}
p_value_adatte <- lapply(test_adatte, function(x) x$p_value)
p_value_inadatte <- lapply(test_inadatte, function(x) x$p_value)
p_value_differenza_di_proporzioni <- c(p_value_adatte, p_value_inadatte)
adjusted_p_values_differenza_di_proporzioni <- p.adjust(p_value_differenza_di_proporzioni, 
                                                        method = "BH")
sort(adjusted_p_values_differenza_di_proporzioni)
```

## 3. Test di McNemar

Il discriminante per usare un metodo o l'altro in questo test è che, data una tavola di contingenza

|$a$|$b$|
|---|---|
|$c$|$d$|


* se $c + d > 6$, allora usiamo il _mid-$p$ test di McNemar_
* se $c + d \leq 6$, allora useremo un **Test Esatto Non Condizionato**

```{r}
limit <- 10 # impostiamo il limite a 10, per motivi didattici (e volendo anche cautelativi)

tavole_di_contingenza[[1]]
tavole_di_contingenza[[1]][1, 2] + tavole_di_contingenza[[1]][2, 1] > limit # controllo cosa succede al primo elemento
tavole_di_contingenza[[9]]
tavole_di_contingenza[[9]][1, 2] + tavole_di_contingenza[[9]][2, 1] > limit 
```

---

Adesso sono pronto ad applicarlo alla `list` 

```{r}
specie_per_mcnemar <- lapply(tavole_di_contingenza, function(x) x[1, 2] + x[2, 1] > limit)

specie_per_test_esatto <- lapply(tavole_di_contingenza, function(x) x[1, 2] + x[2, 1] <= limit)
```

---

In questo caso ci chiediamo se la proporzione di plot dove c'è la _Douglasia_ è uguale o meno a quella in cui troviamo le altre specie.

* L'ipotesi $H_0$ è che le proporzioni di plot dove c'è la _Douglasia_ sia uguale a quella in cui troviamo le altre specie, in generale possiamo dire che tutte le specie abbiano la stessa presenza della _Douglasia_

---

```{r}
tavole_per_mcnemar <- tavole_di_contingenza[specie_per_mcnemar$Value]
tavole_per_test_esatto <- tavole_di_contingenza[specie_per_test_esatto$Value]
```

Si applica il _**mid-$p$ Test**_ a chi si può applicare:

```{r}
mid_p_mcnemar <- lapply(tavole_per_mcnemar, 
                        function(x) mcnemar_midp(x, verbose = FALSE)$mid.p)
```

Si applica il **test esatto non condizionale** agli altri:

```{r}
library(rcompanion)
p_val_symmetry <- lapply(tavole_per_test_esatto, 
                         function(x) nominalSymmetryTest(x, digits = 3))
```

---

Dobbiamo scoprire come è fatta la struttura dell'oggetto sputato fuori dalla funzione `nominalSymmtryTest()` per andare a recuperare i p_value:

```{r}
str(p_val_symmetry[1])
```

```{r}
p_val_symmetry[[1]]
```

---

```{r}
p_val_symmetry[[1]]$Global.test.for.symmetry
```

```{r}
p_val_symmetry[[1]]$Global.test.for.symmetry$p.value
```

Ecco dove sono i p-value, andiamo a recuperarli

```{r}
p_val_symmetry <- lapply(p_val_symmetry, function(x) x$Global.test.for.symmetry$p.value)
```

---

Si rimettono insieme tutti i p-value e si correggono per le correlazioni multiple:

```{r}
p_generali_mcnemar <- c(mid_p_mcnemar, p_val_symmetry)
adj_p_mcnemar <- p.adjust(p_generali_mcnemar, method = "BH")
sort(round(adj_p_mcnemar, 5))

```

