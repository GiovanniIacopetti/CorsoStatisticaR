---
title: "Lez_2x2: Tavole (o tabelle) di contingenza"
output: 
        ioslides_presentation:
                widescreen: true
                df_print: paged
                css: style.css
        github_document:
                toc: TRUE
                # toc_depth: 3 # default = 3
                # fig_width: 7 # default = 7
                # fig_height: 5 # default = 5
        # slidy_presentation:
        #         footer: 'corso di analisi dei dati 2018-2019'
        #         duration : 120

always_allow_html: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
```

```{r, include=FALSE}
kab <- function(...) {
    kable_styling(kable(...))
}
```


# La teoria

## Tabelle di contingenza 2x2 | che faccia hanno

Nelle tabelle di contingenza vengono riassunti i dati di due variabili binomiali (cioè di tipo qualitativo che possono assumere solo due valori).

* Vero/Falso, 
* Presente/Assente
* Cane/Gatto
* ecc/ecc

Si ricorda che le categorie devono essere **esclusive** ed **esaustive**:

* **Esclusive**: nessun dato può ricadere simultaneamente in tutte e due
* **Esaustive**: tutti i dati possono essere assegnati a una o all'altra categoria

---

I campioni devono in teoria essere **indipendenti**, non devono cioè essere legati uno all'altro in modo particolare, come ad esempio 20 persone di 8 famiglie.  

Come abbiamo osservato più volte questa difficoltà viene spesso ignorata.

---

Se le due variabili possono essere considerate causa/effetto per questioni storiche si preferisce mettere le cause come nomi delle righe, gli effetti come nomi delle colonne.

Per i fini statistici è indifferente quale variabile è sulle righe e quale sulle colonne.

---

Partendo da una tabella contenente dati di questo tipo:

```{r, echo=FALSE}
ID <- 1:10
Specie <- as.factor(c("Quercia", "Pino", "Pino", "Quercia", "Quercia", "Quercia", "Pino", "Pino", "Pino", "Pino"))
Danno <- as.factor(c("Danno", "Danno", "Danno", "Sano",  "Sano",  "Sano",  "Sano",  "Sano",  "Sano",  "Sano"))

Dati_1 <- data.frame(ID = ID, Specie = Specie, Danno = Danno)
kab(Dati_1)
```

---

si passa a una tabella di contingenza:  

```{r, echo=FALSE}
Dati_1 <- table(Dati_1$Danno, Dati_1$Specie)

kab(Dati_1)
```

_**Non è rilevante quale variabile finisce sulle righe e quale sulle colonne**_

I numeri nella tabella rappresentano il numero dei campioni che presentano contemporaneamente le aratteristiche indicate dalla loro riga e dalla loro colonna:

Ad esempio abbiamo: 

* 2 pini danneggiati
* una quercia danneggiata
* 4 pini sani
* 3 querce sane

## A cosa servono:

A rispondere a 3 specifiche domande:

1. I due criteri di classificazione (le due variabili) sono indipendenti?
2. Uno dei due valori di una variabile è più comune in uno dei valori della seconda variabile? (c'è una differenza con il punto 2)
3. La proporzione di una variabile è uguale a quella dell'altra?

Nel nostro caso cerchiamo di tradurre le domande:

1. La specie di una pianta e la sua probabilità di essere danneggiata sono indipendenti?
2. I danni sono più comuni fra i pini o fra le quercie?
3. La proporzione di piante danneggiate è uguale alla proporzione delle quercie?

_vale la pena di notare che la domanda numero 3 ha poco senso, il caso è opposto però con altri tipi di dati, in particolare quelli di misure ripetute:_

---

Nel caso di dati derivanti da misure pre-post trattamento:

<div style="float: left; width: 50%;">

La tabella:

```{r, echo=FALSE}
ID <- 1:10
Seme <- as.factor(c("Seme Infetto", "Seme Sano", "Seme Sano", "Seme Infetto", "Seme Infetto", "Seme Infetto", "Seme Sano", "Seme Sano", "Seme Sano", "Seme Sano"))
Semenzale <- as.factor(c("Semenzale Infetto", "Semenzale Infetto", "Semenzale Infetto", "Semenzale Sano",  "Semenzale Sano",  "Semenzale Sano",  "Semenzale Sano",  "Semenzale Sano",  "Semenzale Sano",  "Semenzale Sano"))

Dati_2 <- data.frame(ID = ID, Seme = Seme, Semenzale = Semenzale)
kab(Dati_2)
```

</div>

<div style="float: right; width: 50%;">

La tavola di contingenza:

```{r, echo=FALSE}
Dati_2 <- table(Dati_2$Seme, Dati_2$Semenzale)

kab(Dati_2)
```

</div>

---

Le nostre tre domande diventano:

1. La probabilità di una pianta di essere danneggiata prima e dopo sono indipendenti?  
_In linea di principio non dovrebbero essere per nulla indipendenti, la suscettibilità di una pianta è dovuta a un sacco di fattori diversi_
2. Il danno dopo il trattamento è più comune fra le piante che erano sane prima?  
_La domanda è complessa e apre scenari interessanti._  
3. La proporzione di danni tra "prima"" e "dopo" il trattamento è diversa?  
_Cioè il trattamento è servito a qualcosa???_

_in questo contesto la domanda numero 3 è generalmente quella più interessante_

## Le risposte

Le risposte a queste tre domande vengono da tre test statistici differenti:

1. Test di indipendenza delle variabili
2. $z$-test per la differenza fra due proporzioni
3. Test di McNemar


## _Excursus sui campioni appaiati:_

Il problema dei campioni appaiati (_paired_) viene eluso quasi completamente da questo approccio.
In moti testi è scritto che il test di McNamar sia da utilizzare in caso di campioni appaiati.  
Come abbiamo visto spesso nel caso di misure ripetute McNamar non è il test _giusto_, ma il test _che risponde alla domanda principale_.

C'è però un altro modo di accoppiare i campioni: quando gli elementi hanno una relazione a coppie rispetto ad una variabile che non vogliamo influenzi i nostri calcoli (ad es. diametro del primo elemento con valore 0 = diametro del primo elemento con valore 1)

In questo caso occorre _controllare per il fattore di appaiamento_ nell'analisi, e un test non appaiato può risultare più efficace. Poiché qui la faccenda si complica ed esula dallo scopo di questa lezione. Si consiglia di consultare [_Pearce, 2015_](https://www.bmj.com/content/352/bmj.i969).


# I test di indipendenza delle variabili

## Condizionamento delle tabelle

Il punto chiave per capire quale test sia opportuno o meno usare è il concetto di _condizionamento_ delle tabelle:

Nonostante le tabelle 2x2 si presentino sotto questa forma:

|$\mathbf{a}$|$\mathbf{b}$|
|---         |---         |
|$\mathbf{c}$|$\mathbf{d}$|

una parte fondamentale è ricoperta dai **totali marginali**:

|||$n_1 = a+b$  |
|---         |---         |---          |
|||$n_2 = c+d$  |
|$n_3 = a+c$ |$n_4 = b+d$  |$N = a+b+c+d$|

---

La domanda è: **quanti di questi totali eravamo in grado di prevedere prima che l'esperimento iniziasse?**

* $N$ non è noto a priori (campioniamo finchè non siamo stanchi, finiamo i soldi, tramonta il sole...).  
_Normalmente questo non succede, ma se succede..._

Questo metodo è noto come campionamento di _Poisson_, la distribuzione delle variabili segue una distribuzione di _Poisson_, invece di una più comune distribuzione _binomiale_.

Nelle tavole di contingenza questo cambia poco perché le variabili di _Poisson_ vengono normalmente trattate come _binomiali_. È importante però non perdere di vista questo dettaglio per altre analisi.

---

* $N$ è stato deciso in ufficio, ma:

* Se non conosciamo **né** righe **né** colonne allora la tabella è _**non condizionata**_
* Se conosciamo solo **o** righe **o** colonne (se per esempio abbiamo impostato noi una delle variabili, magari con 50% dei casi $A$, e 50% $B$) come nella **stragrande maggioranza dei disegni sperimentali**, allora la tabella è di tipo intermedio (_**singly conditioned**_)
* Se conosciamo tutti i totali marginali, allora la tabella è _**condizionata**_. Questo è il caso solo se anche _chi_ fornisce la variabile dipendente conosce in anticipo la distribuzione della variabile indipendente. Questo caso non si verifica quasi mai.

---

Cosa succede adesso?

Normalmente per ogni tipologia di tabella la letteratura consiglia un diffferente test statistico, e tecnicamente questo è corretto. In generale però possiamo semplificarci abbastanza la vita e dare delle indicazioni di massima.

Segue un breve elenco dei test statistici che dovete conoscere, e quindi delle indicazioni su quando usare l'uno o l'altro.

---

## Test del $\chi^2$ (chi-quadro) di Pearson | _Pearson's chi-squared test_

**Karl Pearson**, non Egon Pearson

Anche noto come:

* test del $\chi^2$ (chi-quadro)
* _goodness-of-fit test_
* _Pearson's goodness-of-fit_

---

_**Desueto e spesso sbagliato**_

**Perché esiste?**

Perché prima dell'avvento dei calcolatori era l'unico calcolabile a mano in tempi ragionevoli.
Ha dei grossi problemi quando N è piccolo (<40) e quando alcune caselle hanno numeri piccoli (<5).
Rappresenta comunque un'approssimazione del valore esatto (che oggi è possibile calcolare senza sforzo).

_**N.B. non c'è alcun motivo per continuare a usarlo!**_

**Perché è importante conoscerlo:**

* per comprendere più facilmente l'idea dietro alla matematica
* perché è tuttora la base di questo tipo di analisi

---

L'idea è di costruire una tabella dei valori attesi e vedere quanto la tabella che abbiamo misurato si discosta da quella dei valori attesi.

la tabella che misuriamo ha questi valori:

|$\mathbf{a}$|$\mathbf{b}$|
|---         |---         |
|$\mathbf{c}$|$\mathbf{d}$|

il primo passo è calcolare i totali marginali:

|$\mathbf{a}$|$\mathbf{b}$|$n_1 = a+b$  |
|---         |---         |---          |
|$\mathbf{c}$|$\mathbf{d}$|$n_2 = c+d$  |
|$n_3 = a+c$ |$n_4 = b+d$  |$N = a+b+c+d$|

___

<div style="float: left; width: 50%;">

Dalla tabella dei totali marginali...

|              |              |$\mathbf{n_1}$|
|---           |---           |---           |
|              |              |$\mathbf{n_2}$|
|$\mathbf{n_3}$|$\mathbf{n_4}$|$\mathbf{N}$  |

</div>
<div style="float: right; width: 50%;">

...si calcolano le frequenze attese:

|$a_{att}=\frac{n_1*n_3}{N}$ |$b_{att}=\frac{n_1*n_4}{N}$ |$\mathbf{n_1}$|
|---           |---           |---           |
|$c_{att}=\frac{n_2*n_3}{N}$ |$d_{att}=\frac{n_2*n_4}{N}$ |$\mathbf{n_2}$|
|$\mathbf{n_3}$|$\mathbf{n_4}$|$\mathbf{N}$  |

</div>

### _!!! Gradi di libertà !!!_  
  
Vale la pena notare che i totali marginali sono considerati il vero dato certo del problema.
in questo caso il grado di libertà della tabella (cioè di $a$, $b$, $c$, e $d$) è in realtà uno solo:
se variassimo $a$, varieremmo di conseguenza anche tutti gli altri valori.

In generale i gradi di libertà di una tabella di contingenza sono:  
$$GDL = (righe-1) * (colonne-1)$$

---

Adesso abbiamo:

<div style="float: left; width: 50%;">

la tabella delle frequenze attese...

|$\mathbf{A_1}$|$\mathbf{A_2}$|
|---         |---         |
|$\mathbf{A_3}$|$\mathbf{A_4}$|

</div>
<div style="float: right; width: 50%;">

...e la tabella delle frequenze osservete:

|$\mathbf{O_1}$|$\mathbf{O_1}$|
|---         |---         |
|$\mathbf{O_3}$|$\mathbf{O_4}$|

</div>

a questo punto si calcola il famigerato $\chi^2$:

$$\chi^2= \sum_{i=1}^{4}\frac{(O_i-A_i)^2}{A_i}$$

---

Questo valore viene confrontato con il valore indicato sulle tabelle del $\chi^2$:

```{r, echo=FALSE}
include_graphics("chi_squared_table.png")
```

consultando la tabella possiamo vedere quale $\alpha$ superiamo sapendo che abbiamo un unico grado di libertà ($GDL = v = 1$)

Se il $\chi^2$ calcolato è più grande ti quello indicato dalla tabella posso rifiutare la mia $H_0$.


## Test esatto di Fisher | _Fisher's Exact test_

**corretto solo in determinati casi**

Noto anche come:

* Fisher-Irwin's test  
* Fisher-Yates' test




---

**Perché è così usato?**

Perché storicamente è il primo test a fornire risultati esatti (anzi che approssimazioni). Fino all'avvento dei calcolatori era molto complesso da calcolare a mano, e anche con i calcolatori per tabelle di contingenza grandi o con N elevati può richiedere metodi di calcolo non banali.

La sua efficacia è valida solo nel caso si rispettino le caratteristiche sperimentali che hanno portato alla sua creazione: in poche parole _le somme marginali della tavola di contingenza devono essere chiaramente stabilite prima dell'esperimento_, la tabella deve essere in pratica **condizionata**.

---

_**N.B. non c'è alcun motivo per continuare a usarlo!**_

**Perché è importante conoscerlo:**

* rappresenta un passo storico nel calcolo della probabilità
* è il test corretto per le tabelle condizionate
* perché è ancora (spesso a torto) molto utilizzato

---

Data la tabella di contingenza

|$\mathbf{a}$|$\mathbf{b}$|$n_1 = a+b$  |
|---         |---         |---          |
|$\mathbf{c}$|$\mathbf{d}$|$n_2 = c+d$  |
|$n_3 = a+c$ |$n_4 = b+d$  |$N = a+b+c+d$|

Fisher dimostrò che la probabilità che una tale configurazione di $a$, $b$, $c$, e $d$ aveva una probabilità di realizzarsi calcolabile:

$$p = \frac{(a+b)!(c+d)!(a+c)!(b+d)!}{a! b! c! d! N}$$

A quel punto si poteva calcolare la probabilità di tutte le tabelle con configurazioni ancora più estreme, entrare nella tabella del $\chi^2$ e ottenere l'agognato **p-value**.

## Dov'è il problema del test di Fisher?

Il proplema è che il test è pensato per un tipo di esperimento particolare, in cui i totali marginali sono noti a priori (nell'esperimento di Fisher sono anche uguali, ma la formula non lo richiede), cosa comporta nella pratica questo:

* chi realizza il controllo conosce la proporzione della variabile indipendente
* anche la variabile indipendente _conosce_ quella proporzione

In pratica questo non succede quasi mai.

L'esperimento per cui il test è stato disegnato è un _caposaldo del metodo scientifico_ e dovrebbe essere noto a tutti: [Lady tasting tea](https://en.wikipedia.org/wiki/Lady_tasting_tea)

## Test del $\chi^2$ con 'N-1' | _'N-1' chi-squared test_

o **Test del $\chi^2$ di Egon Pearson** (non Karl Pearson)

Equivalente al **Test del $\chi^2$ di Mantel‐Haenszel** (Mantel‐Haenszel chi‐squared test) per tabelle 2x2 **senza correzioni per la continuità**.

Possiamo considerarlo come una variante del test classico del $\chi^2$, quello di Karl pearson, in cui però $$\chi^2_{N-1} = \chi^2 * \frac{N-1}{N}$$

Questo test è al momento uno dei più robusti da utilizzare nell'analisi delle tavole 2x2 nel caso in cui non siano condizionate o siano semi-condizionate.

## Altre cose che succedono nei test di indipendenza delle variabili:

### $\chi^2$ con la correzione per la continuità di Yates
Yates voleva correggere il $\chi^2$ per ottenere valori simili al test esatto di Fisher, perché quello era troppo difficile da calcolare. Ora esistono i computer.


## Quale test usare?

Il dibattito attorno a quale test utilizzare sembra non terminare mai, ma qui si seguiranno le indicazioni di [Campbell 2007](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2832):

_NB: le indicazioni non rappresentano lo stato dell'arte, che si può seguire sull'interessante [nota all'articolo di Andrés](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3169) ma sono nondimeno un solido punto di partenza._

Tabelle non condizionate o semi-condizionate:

* Se la tabella contiene uno 0, si usa il **test esatto di Fisher-Irwin secondo la regola di Irwin** (Fisher-Irwin test by Irwin's rule)
* Altrimenti si usa il **test del $\chi^2$ con 'N-1'** ('N-1' chi-squared test)

Tabelle condizionate:

* **Test esatto di Fisher.**


# Test per la differenza di proporzioni:


## Quale scegliere:

Storicamente si è sempre utilizzato lo **$z$-test per la differenza fra due proporzioni**.  
Normalmente però si tratta di campioni enormi, che spesso nei nostri casi mancano.  
In generale:

* Se tutte le celle sono >30 si può tranquillamente ustilizzare lo **$z$-test**
* Se tutte le celle sono >10 la _letteratura_ raccomanda comunque lo **$z$-test**
* Se anche una sola cella ha meno di 10 campioni si passa ai **metodi di simulazione**


## $z$-test per la differenza fra due proporzioni | _Two proportions $z$-test_

**ASSUNTI**: nessuna casella è minore di 10!

Ricordiamo che lo $z$-test è la versione del $t$-test che usa direttamente la distribuzione normale invece della $t$ di Student.

In questo caso non si usa il $t$-test, che sembrerebbe il più corretto, avendo per le mani degli stimatori e non i valori noti, perché i numeri sono abbastanza grandi da evitarci il $t$-test.  
Queti motivi non mi sono chiarissimi, _chi avesse voglia di lanciarsi in un po' di simulazioni per vedere le differenze è il benvenuto._

## Metodi di simulazione:

Tornando alla tabella

```{r, echo=FALSE}
kab(Dati_1)
```

vogliamo controllare se i pini sono davvero più malati delle quercie.

* L'ipotesi $H_0$ è che le proporzioni di piante malate derivino da un'unica popolazione che non differenzia rispetto alla specie: $$H_0 : p_{pini} - p_{quercie} = 0$$
* Calcoliamo la differenza di proporzioni dei dati è 
$$\hat{p}_{pini} - \hat{p}_{quercie} = \frac{2}{6} - \frac{1}{4} \approx 0.0832$$

---

Il procedimento è piuttosto lineare:

1. Si prendono 3 carte nere e 7 carte rosse (le nere per le piante malate, le rosse per le piante sane)
2. Dividiamo le carte in un gruppo da sei (i pini) e uno da 4 (le quercie)
3. Calcoliamo di nuovo $\hat{p}_{pini} - \hat{p}_{quercie}$ e lo segnamo
4. Ripetiamo i passi 2 e 3 un **botto di volte**, tipo 1000.
5. Vediamo in che percentuale di casi il valore supera $0.0832$ (che avevamo ottenuto dalla tabella)
6. Dividiamo la percentuale per 100 e otteniamo il nostro p-value

In pratica si calcola un p-value di forza bruta. La cosa è fattibile quasi solo con l'ausilio del calcolatore.

## Altre cose che succedono nei test di differenza fra proporzioni:

Storicamente un approccio comune era il seguente:

* Campioni numerosi (>30 per ogni cella): Pearson's chi-square
* Campioni intermedi (>10 per ogni cella): Yates' chi-square
* Campioni piccoli (anche una cella <10): Fisher's exact test

_Upton (1982)_ e _D'Agostino (1988)_ eliminano dal gioco sia Yates che Fisher


# Test di McNemar




## Per approfondire:
[Una pagina di partenza per le Tavole di Contingenza](http://www.jerrydallal.com/LHSP/ctab.htm)

[Quando usare il test di McNemar](https://stats.stackexchange.com/a/141450/232657)

[Conditional versus Unconditional Exact Tests for Comparing Two Binomials, 2003](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.572.632&rep=rep1&type=pdf)

# la pratica

## I dati di partenza

Carichiamo i dati da un foglio Excel:

```{r, message=FALSE}
library(readxl)
read_excel(path = "data.xlsx")
```

Le specie sono state mescolate per mantenere la riservatezza del dataset.  
L'unica variabile corretta è `Pseudotsuga menziesii`, che è la specie di riferimento delle misurazioni.

---

I numeri son abbondanze relative (percentuali di copertura) di diverse specie.  
La tabella ha (come dovrebbe) le specie sulle colonne, le misure di copertura sulle righe.

Controlliamo la tabella:

```{r}
DB <- read_excel(path = "data.xlsx")[, -1] # eliminiamo la colonna con i nomi
str(DB)
```

---

La colonna del castagno è stata identificata come `chr` perché alcune caselle hanno dei `.` invece che `0`. Si correggono subito e si trasforma di nuovo la variabile in `num`:

```{r}
DB$`Castanea sativa`[DB$`Castanea sativa` == "."] <- 0 # spazi nei nomi delle 
# colonne ci costringono a usare gli apici ` [alt + \]

# Non la metto subito al suo posto nel DB perché facilmente con as.numeric si 
# perdono dei dati che potrei voler ricostruire
Castanea_sativa <- as.numeric(DB$`Castanea sativa`) 
```

Il programma avvisa che uno dei valori non era numerico, e quindi è stato perso.

---

Confrontiamo i `NA` della colonna del `DB` con quelli della variabile `Castanea_sativa`

```{r}
DB$`Castanea sativa`[is.na(Castanea_sativa) & !is.na(DB$`Castanea sativa`)]
```

Questa `O` al posto dello `0` è un problema classico, si corregge facilmente:

```{r}
Castanea_sativa[DB$`Castanea sativa` == "O"] <- 0
DB$`Castanea sativa` <- Castanea_sativa
```

```{r}
sum(is.na(DB)) # in queste tabelle se ci sono zeri non ci dovrebbero essere NA
```

---

Ce sono 3 `NA` che non si spiegano, in questo caso:

1. Si ricontrollano i cartacei da cui sono stati trascritti i dati
2. Si chiedono delucidazioni al rilevatore
3. Si sceglie se imputare i dati mancanti o recuperarli in qualche altro modo

Nel nostro caso erano degli errori di battitura di celle che avrebbero dovuto essere `0`.

```{r}
DB$`Castanea sativa`[is.na(DB$`Castanea sativa`)] <- 0
```


```{r}
min(DB) # mi aspetto che il minimo sia 0, e conti come assenza
max(DB) # che sia sopra il 100% non è un problema, se è spiegato nei M&M
```

---

È importante che le variabili siano di tipo **binomiale**, in questo caso dati di presenza/assenza.

La prassi è sostituire tutte le coperture `>0` con un `1`.

```{r}
DB[DB > 0] <- 1
```


## La tabella di contingenza

Consideriamo le variabili `Pseudotsuga menziesii` e `Clematis vitalba`:

```{r}
PSEMEN <- DB$`Pseudotsuga menziesii`
CLEVIT <- DB$`Clematis vitalba`
```

la tabella di contingenza si crea con un solo comando:

```{r}
tavola_PSEMEN_CLEVIT <- table(PSEMEN, CLEVIT)
tavola_PSEMEN_CLEVIT
```

## Presupposti delle misure

**Il campionamento è di tipo multinomiale**: il numero dei plot da misurare è stato deciso prima di iniziare le misure.

**La tabella non è condizionata**: una volta arrivati sui plot si sono scelti punti con un principio completamente indipendente dalla presenza o meno di _Douglasia_ o di _vitalba_, i totali marginali non erano assolutamente prevedibili.

## Le nostre 3 domande

Ritorniamo alle nostre 3 specifiche domande:

1. I due criteri di classificazione (le due variabili) sono indipendenti?
2. Uno dei due valori di una variabile è più comune in uno dei valori della seconda variabile? (c'è una differenza con il punto 2)
3. La proporzione di una variabile è uguale a quella dell'altra?

Nel nostro caso cerchiamo di tradurre le domande:

1. La presenza della _Douglasia_ è indipendente da quella della _vitalba_
2. La _Douglasia_ si rinnova meno dove c'è la _vitalba_?
3. La proporzione di plot con la _Douglasia_ è uguale alla proporzione di plot con la _vitalba_?

_vale la pena di notare che la domanda numero 3 in questo caso può essere interessante, come no_

## P-hacking | cose che tutti fanno ma nessuno lo dice!

È importante riconoscere che le domande dovrebbero essere state decise **prima di andare in campo**, solo in questo caso i p-value hanno un vero significato.

* siamo ancora nel campo dell'_hypotesis testing_

Sel la domanda viene scelta dopo aver visto i dati (ma a un buon forestale spesso basta vedere il bosco) i p-value diventano solo indicativi, e siamo tenuti a scriverlo a chiare lettere:

* siamo nel campo delle _analisi esplorative_

## 1. Test di indipendenza delle variabili

Nessuna delle caselle è `0`, quindi si procede con il **'N-1' Pearson's Chi-Squared Test**
Si ricorda che nel caso **2x2** il test è equivalente al **Mantel-Haenszel Chi-Squared senza la correzione per la continuità** 

Prima si crea un vettore necessario per il test composto da un numero N di cifre uguali:

```{r}
stratum <- rep(1, length(PSEMEN)) # la lunghezza di una qualsiasi variabile è = N
```

La funzione `mantelhaen.test()` nel nostro caso ha bisogno di 4 argomenti:

1. La prima variabile
2. La seconda variabile
3. Un vettore che identifichi gli strati (nel nostro caso tutto uguale)
4. `correct = FALSE`, per evitare di applicare la _correzione per la continuità_

---

```{r}
mantelhaen.test(PSEMEN, CLEVIT, stratum, correct = FALSE)
```

Nel nostro caso il p-value è ben maggiore di 0.05. Le variabili risultano indipendenti.

## 2. Test per la differenza di proporzioni

In questo caso ci chiediamo se ci sia più _vitalba_ dove la _Douglasia_ non si rinnova:

* L'ipotesi $H_0$ è che le proporzioni di _vitalba_ derivino da un'unico tipo di plot, che non risente della rinnovazione o meno della douglasia, in questo caso $p$ è la proporzione di plot con rinnovazione di _vitalba_: $$H_0 : p_{NOdouglasia} - p_{douglasia} = 0$$
* Calcoliamo la differenza di proporzioni dei dati è 
$$\hat{p}_{NOdouglasia} - \hat{p}_{douglasia} = \frac{6}{9} - \frac{7}{19}$$

---

```{r}
diff_p <- (tavola_PSEMEN_CLEVIT[1, 2]/sum(tavola_PSEMEN_CLEVIT[1, ])) - (tavola_PSEMEN_CLEVIT[2, 2]/sum(tavola_PSEMEN_CLEVIT[2, ]))
diff_p
```

La funzione vuole le variabili inserite come colonne di un `data.frame`, e nel caso di variabili qualitative (come le nostre) che siano colonne di tipo `factor` invece che `numeric`

```{r}
data <- data.frame(CLEVIT = as.factor(CLEVIT), PSEMEN = as.factor(PSEMEN))
```

---

```{r, message=FALSE}
library(statsr)
inference(CLEVIT, PSEMEN, data = data, type = "ht", statistic = "proportion", 
          success = "1", method = "simulation", order = c("0", "1"), null = 0, 
          alternative = "greater", nsim = 10000, 
          show_eda_plot = FALSE, show_inf_plot = FALSE)
```

---

```{r, message=FALSE}
inference(CLEVIT, PSEMEN, data = data, type = "ht", statistic = "proportion", 
          success = "1", method = "simulation", order = c("0", "1"), null = 0, 
          alternative = "greater", nsim = 10000, 
          show_var_types = FALSE, show_summ_stats = FALSE, show_res = FALSE)
```

